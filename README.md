# ğŸ˜Š Facial Emotion Recognition using CNN (Keras + TensorFlow)

This project implements a **Convolutional Neural Network (CNN)** to detect and classify human emotions from facial images.  
It uses **TensorFlow/Keras** for deep learning and can recognize key emotions such as **Happy, Sad, Angry, Surprise, Fear, Disgust, and Neutral**.

---

## ğŸš€ Features

- ğŸ§  Deep learning model built using **Keras (TensorFlow backend)**
- ğŸ–¼ï¸ Works with grayscale facial images
- ğŸ“Š Visualizations for accuracy, loss, and confusion matrix
- âš™ï¸ Easily extensible for custom datasets or transfer learning
- ğŸ§© Preprocessing pipeline for resizing, normalization, and data augmentation

---

## ğŸ§© Project Structure

```
facial-emotion-recognition/
â”‚
â”œâ”€â”€ train_model.py                # Main CNN model training script
â”œâ”€â”€ evaluate_model.py             # Model testing & visualization
â”œâ”€â”€ model/                        # Saved model weights and architecture
â”œâ”€â”€ dataset/                      # Training and validation images
â”œâ”€â”€ facial_emotion_recognition_requirements.txt  # Project dependencies
â””â”€â”€ README.md                     # Documentation
```

---

## ğŸ“¦ Requirements

Make sure you have **Python 3.8+** installed.

Install dependencies:
```bash
pip install -r facial_emotion_recognition_requirements.txt
```

---

## ğŸ§  Dataset

You can use publicly available datasets such as:

- **[FER-2013 Dataset](https://www.kaggle.com/datasets/msambare/fer2013)** (Kaggle)
- **[CK+ Dataset](https://www.kaggle.com/datasets/shawon10/ckplus)**

Organize dataset folders as follows:

```
dataset/
â”‚
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ angry/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ sad/
â”‚   â”œâ”€â”€ surprise/
â”‚   â”œâ”€â”€ fear/
â”‚   â”œâ”€â”€ disgust/
â”‚   â””â”€â”€ neutral/
â”‚
â””â”€â”€ test/
    â”œâ”€â”€ angry/
    â”œâ”€â”€ happy/
    â”œâ”€â”€ sad/
    â”œâ”€â”€ surprise/
    â”œâ”€â”€ fear/
    â”œâ”€â”€ disgust/
    â””â”€â”€ neutral/
```

---

## âš™ï¸ Model Architecture (Example)

- **Input:** 48x48 grayscale image  
- **Conv2D â†’ ReLU â†’ MaxPooling** layers  
- **Dropout** for regularization  
- **Flatten â†’ Dense â†’ Softmax** output (7 emotion classes)

---

## ğŸ§© Example Code Snippet

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Build model
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dense(7, activation='softmax')
])

# Compile
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

---

## ğŸ“Š Training Example

```bash
python train_model.py
```

Monitor progress:
```
Epoch 10/50
loss: 0.6123 - accuracy: 0.7924
val_loss: 0.7321 - val_accuracy: 0.7510
```

---

## ğŸ“ˆ Evaluation

Visualize model performance:
```bash
python evaluate_model.py
```

- Confusion Matrix  
- Classification Report  
- Accuracy & Loss Curves  

---

## ğŸ§  Example Output

| Emotion | Example |
|----------|----------|
| ğŸ˜€ Happy | ![happy](https://upload.wikimedia.org/wikipedia/commons/8/89/Portrait_Man_Smile.jpg) |
| ğŸ˜¢ Sad | ![sad](https://upload.wikimedia.org/wikipedia/commons/4/4f/Man_crying.jpg) |

---

## âš™ï¸ Future Enhancements

- ğŸ” Real-time emotion recognition using webcam (OpenCV)
- ğŸ§© Transfer learning with MobileNet or EfficientNet
- ğŸ›ï¸ Flask or Streamlit web app integration
- ğŸŒ Multimodal emotion fusion (text + face)

---

## ğŸ‘¨â€ğŸ’» Author

**Jeevan Reddy**  
Built with â¤ï¸ using Python, TensorFlow, and Keras.

---

## âš–ï¸ License

This project is released under the **MIT License**.  
Feel free to use, modify, and distribute with attribution.

---
